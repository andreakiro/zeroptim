{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "from zeroptim.mlp import MLP\n",
    "from zeroptim.data import loader\n",
    "from zeroptim.utils import parse_yaml_config\n",
    "from zeroptim.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeroptim.optimizers.mezo import MeZO\n",
    "from zeroptim.optimizers.smartes import SmartES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load standard mlp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader('mnist-digits')\n",
    "first_batch = next(iter(dataloader))\n",
    "inputs, targets = first_batch\n",
    "print(\"Shape of inputs:\", inputs.shape)\n",
    "print(\"Shape of targets:\", targets.shape)\n",
    "inputs.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader('mnist-digits')\n",
    "m = MLP(**parse_yaml_config('mlp.yaml'))\n",
    "opt = torch.optim.SGD(m.parameters(), lr=1e-3)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define benchmark loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model, loader, opt, criterion, train_iters=1000):\n",
    "\n",
    "    def closure(inputs, targets, with_backward=False):\n",
    "        # optimization-step closure :)\n",
    "        opt.zero_grad()\n",
    "        loss = criterion(model(inputs), targets)\n",
    "        if with_backward: loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    def func_fwd(*params):\n",
    "        for name, p in zip(names, params):\n",
    "            set_attr(m, name.split(\".\"), p)\n",
    "        return crit(m(inputs), targets)\n",
    "\n",
    "    losses = []\n",
    "    jvps, vhvs = [], []\n",
    "    n_iters = 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch_idx in (pbar := trange(int(train_iters))):\n",
    "        if n_iters >= train_iters: break\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "            if n_iters >= train_iters: break\n",
    "\n",
    "            inputs = inputs.flatten(start_dim=1)\n",
    "            prev_params = tuple([p.clone() for p in model.parameters()])\n",
    "            \n",
    "            # take optimization step\n",
    "            loss = opt.step(\n",
    "                lambda: closure(\n",
    "                    inputs, targets, \n",
    "                    with_backward=not isinstance(opt, (MeZO, SmartES))\n",
    "                )\n",
    "            )\n",
    "\n",
    "            cur_params = tuple([p.clone() for p in model.parameters()])\n",
    "            vs = tuple([p2.detach() - p1.detach() for p2, p1 in zip(cur_params, prev_params)])\n",
    "\n",
    "            # compute jvp and vhp\n",
    "            tmp_params, names = make_functional(model)\n",
    "            _, jvp = torch.autograd.functional.jvp(func_fwd, prev_params, vs)\n",
    "            _, hvp = torch.autograd.functional.vhp(func_fwd, prev_params, vs)\n",
    "            vhv = sum((v * hv).sum() for v, hv in zip(vs, hvp))\n",
    "            restore_functional(model, tmp_params, names)\n",
    "\n",
    "            # append metrics\n",
    "            losses.append(loss.item())\n",
    "            jvps.append(jvp.item())\n",
    "            vhvs.append(vhv.item())\n",
    "\n",
    "            # update tqdm bar\n",
    "            pbar.set_description(f'train loss: {loss.item():.3f}')\n",
    "            pbar.update(1)\n",
    "            n_iters += 1\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return losses, jvps, vhvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, jvps, vhvs = benchmark(m, dataloader, opt, crit, train_iters=30*len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, label='SGD', color='C0', linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(jvps, label='jvps', color='C2', linestyle='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(vhvs, label='vhvs', color='C1', linestyle='--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-mezo-qrlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
